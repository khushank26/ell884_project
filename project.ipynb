{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":914551,"sourceType":"datasetVersion","datasetId":491586}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers datasets sqlparse torch sentencepiece accelerate","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T08:44:00.975258Z","iopub.execute_input":"2025-04-27T08:44:00.975500Z","iopub.status.idle":"2025-04-27T08:45:17.296682Z","shell.execute_reply.started":"2025-04-27T08:44:00.975472Z","shell.execute_reply":"2025-04-27T08:45:17.295965Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.1)\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\nRequirement already satisfied: sqlparse in /usr/local/lib/python3.11/dist-packages (0.5.3)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\nRequirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.3.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nCollecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.16)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.0.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, fsspec, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.9.90\n    Uninstalling nvidia-curand-cu12-10.3.9.90:\n      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.3.2\n    Uninstalling fsspec-2025.3.2:\n      Successfully uninstalled fsspec-2025.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed fsspec-2024.12.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import json\nimport pandas as pd\n\n# Load training data\nwith open(\"/kaggle/input/yale-universitys-spider-10-nlp-dataset/spider/train_spider.json\") as f:\n    train_data = json.load(f)\n\n# Load dev (validation) data\nwith open(\"/kaggle/input/yale-universitys-spider-10-nlp-dataset/spider/dev.json\") as f:\n    dev_data = json.load(f)\n\n# Load database schemas (for schema linking)\nwith open(\"/kaggle/input/yale-universitys-spider-10-nlp-dataset/spider/tables.json\") as f:\n    tables_data = json.load(f)\n\n# Create a schema dictionary {db_id: schema_info}\ndb_schemas = {db[\"db_id\"]: db for db in tables_data}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T08:47:55.244203Z","iopub.execute_input":"2025-04-27T08:47:55.244904Z","iopub.status.idle":"2025-04-27T08:47:55.676182Z","shell.execute_reply.started":"2025-04-27T08:47:55.244877Z","shell.execute_reply":"2025-04-27T08:47:55.675421Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Check the structure of the first entry in tables.json\nprint(db_schemas[list(db_schemas.keys())[0]])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T08:49:22.917516Z","iopub.execute_input":"2025-04-27T08:49:22.917799Z","iopub.status.idle":"2025-04-27T08:49:22.922772Z","shell.execute_reply.started":"2025-04-27T08:49:22.917777Z","shell.execute_reply":"2025-04-27T08:49:22.921865Z"}},"outputs":[{"name":"stdout","text":"{'column_names': [[-1, '*'], [0, 'perpetrator id'], [0, 'people id'], [0, 'date'], [0, 'year'], [0, 'location'], [0, 'country'], [0, 'killed'], [0, 'injured'], [1, 'people id'], [1, 'name'], [1, 'height'], [1, 'weight'], [1, 'home town']], 'column_names_original': [[-1, '*'], [0, 'Perpetrator_ID'], [0, 'People_ID'], [0, 'Date'], [0, 'Year'], [0, 'Location'], [0, 'Country'], [0, 'Killed'], [0, 'Injured'], [1, 'People_ID'], [1, 'Name'], [1, 'Height'], [1, 'Weight'], [1, 'Home Town']], 'column_types': ['text', 'number', 'number', 'text', 'number', 'text', 'text', 'number', 'number', 'number', 'text', 'number', 'number', 'text'], 'db_id': 'perpetrator', 'foreign_keys': [[2, 9]], 'primary_keys': [1, 9], 'table_names': ['perpetrator', 'people'], 'table_names_original': ['perpetrator', 'people']}\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"from transformers import T5Tokenizer, T5ForConditionalGeneration\n\ntokenizer = T5Tokenizer.from_pretrained('t5-base')\nmodel = T5ForConditionalGeneration.from_pretrained('t5-base')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T08:56:21.748612Z","iopub.execute_input":"2025-04-27T08:56:21.748962Z","iopub.status.idle":"2025-04-27T08:56:52.294353Z","shell.execute_reply.started":"2025-04-27T08:56:21.748914Z","shell.execute_reply":"2025-04-27T08:56:52.293448Z"}},"outputs":[{"name":"stderr","text":"2025-04-27 08:56:35.711562: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1745744195.955882      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1745744196.019449      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d376aa77b5614bec94935d32dfd8e9fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"abcb10c615d5432ca17a5c8fa6627aa8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37f71636552c4fed8d485b3ea797bd3b"}},"metadata":{}},{"name":"stderr","text":"You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\nXet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"545a644f985c41fbbefee1a378445ad8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b33e056337344851afe124011ad4a44f"}},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"import json\nfrom pathlib import Path\n\n# Set your paths (change this if needed)\ndata_dir = Path('/kaggle/input/yale-universitys-spider-10-nlp-dataset/spider')\n\n# Load Spider files\nwith open(data_dir / 'train_spider.json', 'r') as f:\n    train_data = json.load(f)\n\nwith open(data_dir / 'tables.json', 'r') as f:\n    tables = json.load(f)\n\n# Build a mapping: db_id -> schema string\ndef build_schema(tables):\n    schemas = {}\n    for table in tables:\n        db_id = table['db_id']\n        schema = []\n        for table_name in table['table_names_original']:\n            schema.append(f\"table: {table_name}\")\n        for column in table['column_names_original']:\n            table_id, column_name = column\n            if table_id >= 0:\n                table_name = table['table_names_original'][table_id]\n            else:\n                table_name = \"none\"\n            schema.append(f\"column: {column_name} (table: {table_name})\")\n        schemas[db_id] = \" | \".join(schema)\n    return schemas\n\n\nschemas = build_schema(tables)\n\n# Prepare (input, output) pairs\ntrain_pairs = []\nfor item in train_data:\n    question = item['question']\n    db_id = item['db_id']\n    sql = item['query']\n\n    schema = schemas[db_id]\n\n    input_text = f\"question: {question} schema: {schema}\"\n    output_text = sql\n\n    train_pairs.append({'input': input_text, 'output': output_text})\n\nprint(f\"Loaded {len(train_pairs)} training examples!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T08:59:26.688396Z","iopub.execute_input":"2025-04-27T08:59:26.688676Z","iopub.status.idle":"2025-04-27T08:59:26.923548Z","shell.execute_reply.started":"2025-04-27T08:59:26.688658Z","shell.execute_reply":"2025-04-27T08:59:26.922905Z"}},"outputs":[{"name":"stdout","text":"Loaded 7000 training examples!\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# ===============================\n# 1. Install + Import Libraries\n# ===============================\n!pip install transformers datasets\n\nimport json\nfrom pathlib import Path\nfrom datasets import Dataset\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration, Seq2SeqTrainer, Seq2SeqTrainingArguments","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T09:01:16.974208Z","iopub.execute_input":"2025-04-27T09:01:16.975022Z","iopub.status.idle":"2025-04-27T09:01:20.169410Z","shell.execute_reply.started":"2025-04-27T09:01:16.974980Z","shell.execute_reply":"2025-04-27T09:01:20.168690Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.1)\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.16)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# ===============================\n# 2. Load Spider Dataset\n# ===============================\ndata_dir = Path('/kaggle/input/yale-universitys-spider-10-nlp-dataset/spider')\n\nwith open(data_dir / 'train_spider.json', 'r') as f:\n    train_data = json.load(f)\n\nwith open(data_dir / 'dev.json', 'r') as f:\n    dev_data = json.load(f)\n\nwith open(data_dir / 'tables.json', 'r') as f:\n    tables = json.load(f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T09:01:37.899501Z","iopub.execute_input":"2025-04-27T09:01:37.899826Z","iopub.status.idle":"2025-04-27T09:01:38.677187Z","shell.execute_reply.started":"2025-04-27T09:01:37.899799Z","shell.execute_reply":"2025-04-27T09:01:38.676280Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# ===============================\n# 3. Preprocessing: Flatten the Schema\n# ===============================\ndef build_schema(tables):\n    schemas = {}\n    for table in tables:\n        db_id = table['db_id']\n        schema = []\n        for table_name in table['table_names_original']:\n            schema.append(f\"table: {table_name}\")\n        for column in table['column_names_original']:\n            table_id, column_name = column\n            if table_id >= 0:\n                table_name = table['table_names_original'][table_id]\n            else:\n                table_name = \"none\"\n            schema.append(f\"column: {column_name} (table: {table_name})\")\n        schemas[db_id] = \" | \".join(schema)\n    return schemas\n\nschemas = build_schema(tables)\n\ndef prepare_examples(data, schemas):\n    examples = []\n    for item in data:\n        question = item['question']\n        db_id = item['db_id']\n        sql = item['query']\n\n        schema = schemas.get(db_id, \"\")\n\n        input_text = f\"question: {question} schema: {schema}\"\n        output_text = sql\n\n        examples.append({'input': input_text, 'output': output_text})\n    return examples\n\ntrain_examples = prepare_examples(train_data, schemas)\ndev_examples = prepare_examples(dev_data, schemas)\n\nprint(f\"Loaded {len(train_examples)} training examples.\")\nprint(f\"Loaded {len(dev_examples)} validation examples.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T09:01:58.143619Z","iopub.execute_input":"2025-04-27T09:01:58.144124Z","iopub.status.idle":"2025-04-27T09:01:58.176976Z","shell.execute_reply.started":"2025-04-27T09:01:58.144099Z","shell.execute_reply":"2025-04-27T09:01:58.176183Z"}},"outputs":[{"name":"stdout","text":"Loaded 7000 training examples.\nLoaded 1034 validation examples.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# ===============================\n# 4. Load Tokenizer and Model\n# ===============================\nmodel_name = \"t5-base\"  # You can change to 't5-base' or 't5-large'\n\ntokenizer = T5Tokenizer.from_pretrained(model_name)\nmodel = T5ForConditionalGeneration.from_pretrained(model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T09:51:09.277498Z","iopub.execute_input":"2025-04-27T09:51:09.277805Z","iopub.status.idle":"2025-04-27T09:51:09.865449Z","shell.execute_reply.started":"2025-04-27T09:51:09.277782Z","shell.execute_reply":"2025-04-27T09:51:09.864810Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"# ===============================\n# 5. Tokenize the Dataset\n# ===============================\ndef preprocess_function(examples):\n    # Tokenize inputs (questions + schema)\n    model_inputs = tokenizer(\n        examples['input'],\n        max_length=512,\n        truncation=True,\n        padding='max_length'  # <--- add padding\n    )\n\n    # Tokenize targets (SQL queries)\n    with tokenizer.as_target_tokenizer():\n        labels = tokenizer(\n            examples['output'],\n            max_length=512,\n            truncation=True,\n            padding='max_length'  # <--- add padding\n        )\n\n    model_inputs['labels'] = labels['input_ids']\n    return model_inputs\n\n\ntrain_dataset = Dataset.from_list(train_examples).map(preprocess_function, batched=True)\ndev_dataset = Dataset.from_list(dev_examples).map(preprocess_function, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T09:51:24.109842Z","iopub.execute_input":"2025-04-27T09:51:24.110147Z","iopub.status.idle":"2025-04-27T09:51:37.792823Z","shell.execute_reply.started":"2025-04-27T09:51:24.110127Z","shell.execute_reply":"2025-04-27T09:51:37.791844Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/7000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd7b7838b4f64ef7abdc88fd3c966ca1"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:3980: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1034 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0c17559480948dfbf06f09b63170dd8"}},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"# ===============================\n# 6. Setup Training Arguments\n# ===============================\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=\"./results\",\n    #evaluation_strategy=\"steps\",\n    save_strategy=\"steps\",\n    logging_strategy=\"steps\",\n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=4,\n    num_train_epochs=2,\n    save_steps=500,\n    eval_steps=500,\n    logging_steps=100,\n    predict_with_generate=True,\n    fp16=True,  # Use mixed precision if GPU supports\n    report_to=\"none\",  # Disable Wandb logging\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T09:52:17.261702Z","iopub.execute_input":"2025-04-27T09:52:17.262135Z","iopub.status.idle":"2025-04-27T09:52:17.296164Z","shell.execute_reply.started":"2025-04-27T09:52:17.262097Z","shell.execute_reply":"2025-04-27T09:52:17.295556Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"# ===============================\n# 7. Create Trainer\n# ===============================\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=dev_dataset,\n    tokenizer=tokenizer,\n)\n\n# ===============================\n# 8. Start Fine-Tuning\n# ===============================\ntrainer.train()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T09:52:21.482569Z","iopub.execute_input":"2025-04-27T09:52:21.483067Z","iopub.status.idle":"2025-04-27T10:36:06.921863Z","shell.execute_reply.started":"2025-04-27T09:52:21.483042Z","shell.execute_reply":"2025-04-27T10:36:06.920986Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/2702171312.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n  trainer = Seq2SeqTrainer(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1750' max='1750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1750/1750 43:42, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>1.116400</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.088400</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.067400</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.053800</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.048000</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.044800</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.041400</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.037100</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>0.036400</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.036300</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>0.032500</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>0.033700</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>0.031600</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>0.033200</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.029100</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>0.031000</td>\n    </tr>\n    <tr>\n      <td>1700</td>\n      <td>0.030600</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1750, training_loss=0.10316231734412057, metrics={'train_runtime': 2624.3494, 'train_samples_per_second': 5.335, 'train_steps_per_second': 0.667, 'total_flos': 8525410467840000.0, 'train_loss': 0.10316231734412057, 'epoch': 2.0})"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"trainer.save_model(\"./t5_spider_finetuned\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T10:38:30.002718Z","iopub.execute_input":"2025-04-27T10:38:30.003126Z","iopub.status.idle":"2025-04-27T10:38:32.797883Z","shell.execute_reply.started":"2025-04-27T10:38:30.003098Z","shell.execute_reply":"2025-04-27T10:38:32.797160Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"def predict_sql(question, schema_text):\n    input_text = f\"question: {question} schema: {schema_text}\"\n    inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True).to(model.device)  # <-- MOVE TO DEVICE\n    outputs = model.generate(**inputs, max_length=512)\n    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n\n# Example\ntest_question = \"What are the names of all singers?\"\ntest_schema = schemas['concert_singer']  # Choose db_id\nprint(predict_sql(test_question, test_schema))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T10:38:36.355531Z","iopub.execute_input":"2025-04-27T10:38:36.356339Z","iopub.status.idle":"2025-04-27T10:38:36.774474Z","shell.execute_reply.started":"2025-04-27T10:38:36.356305Z","shell.execute_reply":"2025-04-27T10:38:36.773631Z"}},"outputs":[{"name":"stderr","text":"Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","output_type":"stream"},{"name":"stdout","text":"SELECT Name FROM singer ORDER BY Song_Name DESC LIMIT 1\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"import json\nimport sqlite3\nfrom tqdm import tqdm\nimport os\nimport sqlparse\n\n# 1. Load dev set\nwith open(\"/kaggle/input/yale-universitys-spider-10-nlp-dataset/spider/dev.json\", \"r\") as f:\n    dev_data = json.load(f)\n\n# 2. Execution checking helper\ndef execute_sql(db_path, sql_query):\n    try:\n        conn = sqlite3.connect(db_path)\n        cursor = conn.cursor()\n        cursor.execute(sql_query)\n        result = cursor.fetchall()\n        conn.close()\n        return result\n    except Exception as e:\n        return None\n\n# 3. Evaluation loop\ndef evaluate(model, tokenizer, schemas, dev_data, db_folder=\"/kaggle/input/yale-universitys-spider-10-nlp-dataset/spider/database\"):\n    exact_match = 0\n    execution_match = 0\n    total = 0\n\n    correct_examples = []\n    wrong_examples = []\n\n    for example in tqdm(dev_data):\n        question = example['question']\n        db_id = example['db_id']\n        gold_sql = example['query']\n\n        # Input text\n        schema_text = schemas[db_id]\n        input_text = f\"question: {question} schema: {schema_text}\"\n        inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True).to(model.device)\n\n        # Predict\n        outputs = model.generate(**inputs, max_length=512)\n        pred_sql = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\n        # Normalize SQLs\n        pred_norm = sqlparse.format(pred_sql, keyword_case=\"lower\", strip_comments=True).strip()\n        gold_norm = sqlparse.format(gold_sql, keyword_case=\"lower\", strip_comments=True).strip()\n\n        # 1. Exact Match\n        if pred_norm == gold_norm:\n            exact_match += 1\n            correct_examples.append((question, pred_sql, gold_sql))\n        else:\n            wrong_examples.append((question, pred_sql, gold_sql))\n\n        # 2. Execution Match\n        db_path = os.path.join(db_folder, db_id, db_id + \".sqlite\")\n        if os.path.exists(db_path):\n            gold_result = execute_sql(db_path, gold_sql)\n            pred_result = execute_sql(db_path, pred_sql)\n\n            if gold_result == pred_result and gold_result is not None:\n                execution_match += 1\n\n        total += 1\n\n    exact_match_acc = exact_match / total\n    execution_acc = execution_match / total\n\n    return exact_match_acc, execution_acc, correct_examples, wrong_examples\n\n# 4. Run\nexact_match_acc, execution_acc, correct_examples, wrong_examples = evaluate(model, tokenizer, schemas, dev_data)\n\nprint(f\"Exact Match Accuracy: {exact_match_acc * 100:.2f}%\")\nprint(f\"Execution Match Accuracy: {execution_acc * 100:.2f}%\")\n\n# 5. Show Examples\nprint(\"\\n✅ Correct Predictions (Sample 5):\")\nfor q, pred, gold in correct_examples[:5]:\n    print(f\"\\nQuestion: {q}\\nPredicted SQL: {pred}\\nGold SQL: {gold}\\n\")\n\nprint(\"\\n❌ Wrong Predictions (Sample 5):\")\nfor q, pred, gold in wrong_examples[:5]:\n    print(f\"\\nQuestion: {q}\\nPredicted SQL: {pred}\\nGold SQL: {gold}\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T10:38:50.449057Z","iopub.execute_input":"2025-04-27T10:38:50.449648Z","iopub.status.idle":"2025-04-27T10:53:02.589009Z","shell.execute_reply.started":"2025-04-27T10:38:50.449625Z","shell.execute_reply":"2025-04-27T10:53:02.588211Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 1034/1034 [14:12<00:00,  1.21it/s] ","output_type":"stream"},{"name":"stdout","text":"Exact Match Accuracy: 3.19%\nExecution Match Accuracy: 15.57%\n\n✅ Correct Predictions (Sample 5):\n\nQuestion: What is the total number of singers?\nPredicted SQL: SELECT count(*) FROM singer\nGold SQL: SELECT count(*) FROM singer\n\n\nQuestion: What are the names of the stadiums without any concerts?\nPredicted SQL: SELECT name FROM stadium WHERE stadium_id NOT IN (SELECT stadium_id FROM concert)\nGold SQL: SELECT name FROM stadium WHERE stadium_id NOT IN (SELECT stadium_id FROM concert)\n\n\nQuestion: Find the number of distinct type of pets.\nPredicted SQL: SELECT count(DISTINCT pettype) FROM pets\nGold SQL: SELECT count(DISTINCT pettype) FROM pets\n\n\nQuestion: How many employees are there?\nPredicted SQL: SELECT count(*) FROM employee\nGold SQL: SELECT count(*) FROM employee\n\n\nQuestion: Count the number of employees\nPredicted SQL: SELECT count(*) FROM employee\nGold SQL: SELECT count(*) FROM employee\n\n\n❌ Wrong Predictions (Sample 5):\n\nQuestion: How many singers do we have?\nPredicted SQL: SELECT count(*) FROM singer GROUP BY name\nGold SQL: SELECT count(*) FROM singer\n\n\nQuestion: Show name, country, age for all singers ordered by age from the oldest to the youngest.\nPredicted SQL: SELECT T1.name , T1.country , T1.age FROM singer AS T1 JOIN singer AS T2 ON T1.name = T2.name WHERE T1.age  T2.age ORDER BY T1.age FROM T1.sänger_in_concert GROUP BY T1.sänger_in_concert AS T3 JOIN singer AS T4 ON T1.song_name = T3.song_name WHERE T3.age Y T2.country\nGold SQL: SELECT name ,  country ,  age FROM singer ORDER BY age DESC\n\n\nQuestion: What are the names, countries, and ages for every singer in descending order of age?\nPredicted SQL: SELECT T1.Name , T2.Country , T1.Age FROM singer AS T1 JOIN singer_in_concert AS T2 ON T1.Singer_ID = T2.Song_Name JOIN concert AS T3 ON T2.Song_ID = T3.Song_ID ORDER BY T3.Age .adjusted.amount DESC LIMIT 1\nGold SQL: SELECT name ,  country ,  age FROM singer ORDER BY age DESC\n\n\nQuestion: What is the average, minimum, and maximum age of all singers from France?\nPredicted SQL: SELECT avg(T1.Name) , min(T2.Min(T1.Age) , max(T2.Age) FROM singer_in_concert WHERE Country = \"France\"\nGold SQL: SELECT avg(age) ,  min(age) ,  max(age) FROM singer WHERE country  =  'France'\n\n\nQuestion: What is the average, minimum, and maximum age for all French singers?\nPredicted SQL: SELECT avg(Age) , min(Age) , max(Age) FROM singer WHERE Name = 'France'\nGold SQL: SELECT avg(age) ,  min(age) ,  max(age) FROM singer WHERE country  =  'France'\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":39}]}